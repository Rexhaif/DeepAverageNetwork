{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import ToktokTokenizer, TweetTokenizer\n",
    "from sklearn.metrics import f1_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10/26 20:24:07 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
      "\u001b[35m[\u001b[0m#ddf9ed 1.2GiB/1.2GiB\u001b[36m(99%)\u001b[0m CN:2 DL:\u001b[32m30MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0mmmm\n",
      "10/26 20:24:38 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /workspace/notebooks/DeepAverageNetwork/cc.en.300.vec.gz\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "ddf9ed|\u001b[1;32mOK\u001b[0m  |    41MiB/s|/workspace/notebooks/DeepAverageNetwork/cc.en.300.vec.gz\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "## Раскомментируйте и скачайте эмбеддинги\n",
    "# aria2c is just faster than wget because it uses multiple threads\n",
    "!aria2c -x 16 -j 16 -s 16 https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "!gzip -d cc.en.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path: str, num_tokens=100_000):\n",
    "    \n",
    "    pad_token = \"<PAD>\"\n",
    "    unk_token = \"<UNK>\"\n",
    "\n",
    "    vocab: Dict[str, int] = dict()\n",
    "    embeddings = list()\n",
    "\n",
    "    with open(path) as f:\n",
    "\n",
    "        vocab_size, embedding_dim = f.readline().strip().split()\n",
    "\n",
    "        vocab_size = int(vocab_size)\n",
    "        embedding_dim = int(embedding_dim)\n",
    "\n",
    "        max_words = vocab_size if num_tokens <= 0 else num_tokens+2\n",
    "\n",
    "        vocab[pad_token] = 0\n",
    "        embeddings.append(np.zeros(embedding_dim))\n",
    "\n",
    "        vocab[unk_token] = 1\n",
    "        embeddings.append(np.ones(embedding_dim))\n",
    "\n",
    "        progress_bar = tqdm(total=max_words-2, desc='Reading embeddings file')\n",
    "\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            token = ' '.join(parts[:-embedding_dim]).lower()\n",
    "\n",
    "            if token in vocab:\n",
    "                continue\n",
    "\n",
    "            word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
    "\n",
    "            vocab[token] = len(vocab)\n",
    "            embeddings.append(word_vector)\n",
    "\n",
    "            progress_bar.update()\n",
    "\n",
    "            if len(vocab) == max_words:\n",
    "                break\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    embeddings = np.stack(embeddings)\n",
    "    \n",
    "    return vocab, embeddings\n",
    "    \n",
    "    assert(len(vocab) == embeddings.shape[0])\n",
    "    \n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем данные из библиотеки\n",
    "Мы сразу получим `torch.utils.data.Dataset`, который сможем передать в `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"tweet_eval\"\n",
    "dataset_name = \"sentiment\"\n",
    "\n",
    "train_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"train\")\n",
    "valid_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"validation\")\n",
    "test_dataset = load_dataset(path=dataset_path, name=dataset_name, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, base_tokenizer, token2index, pad_token, unk_token, max_length):\n",
    "        \n",
    "        self._base_tokenizer = base_tokenizer  # например ToktokTokenizer()\n",
    "        \n",
    "        self.token2index = token2index  # словарь из load_embeddings()\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.token2index[self.pad_token]\n",
    "        \n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = self.token2index[self.unk_token]\n",
    "        \n",
    "        self.max_length = max_length\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно разделить строку текста на токены\n",
    "        \"\"\"\n",
    "        return self._base_tokenizer.tokenize(text)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно перевести список токенов в список с индексами этих токенов\n",
    "        \"\"\"\n",
    "        indexes = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.token2index:\n",
    "                indexes.append(self.token2index[token])\n",
    "            else:\n",
    "                indexes.append(self.unk_index)\n",
    "        return indexes\n",
    "        \n",
    "    def padding(self, tokens_indices):\n",
    "        \"\"\"\n",
    "        В этом методе нужно сделать длину tokens_indices равной self.max_length\n",
    "        Опционально убрать повторяющиеся unk'и\n",
    "        \"\"\"\n",
    "        padded_indexes = [self.pad_index] * self.max_length\n",
    "        unpadded_indexes = tokens_indices if len(tokens_indices) <= self.max_length else tokens_indices[:self.max_length]\n",
    "        for i, idx in enumerate(unpadded_indexes):\n",
    "            padded_indexes[i] = idx\n",
    "            \n",
    "        return padded_indexes\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно перевести строку с текстом в вектор с индексами слов нужно размера (self.max_length)\n",
    "        \"\"\"\n",
    "        return self.padding(self.indexing(self.tokenize(text)))\n",
    "        \n",
    "    def collate(self, batch):\n",
    "        \n",
    "        tokenized_texts = list()\n",
    "        labels = list()\n",
    "        \n",
    "        for sample in batch:\n",
    "            tokenized_texts.append(self(sample['text']))\n",
    "            labels.append(sample['label'])\n",
    "            \n",
    "        tokenized_texts = torch.LongTensor(tokenized_texts)  # перевод в torch.Tensor\n",
    "        labels = torch.LongTensor(labels)  # перевод в torch.Tensor\n",
    "        \n",
    "        return tokenized_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d59165f2ffd43bbbb3e2673d5c38204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading embeddings file:   0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token2index, embeddings = load_embeddings(\"cc.en.300.vec\", 500000)\n",
    "base_tokenizer = TweetTokenizer(reduce_len=True)\n",
    "tokenizer = Tokenizer(base_tokenizer, token2index, \"<PAD>\", \"<UNK>\", 128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=tokenizer.collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, collate_fn=tokenizer.collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=tokenizer.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(isinstance(x, torch.Tensor))\n",
    "assert(len(x.size()) == 2)\n",
    "\n",
    "assert(isinstance(y, torch.Tensor))\n",
    "assert(len(y.size()) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Я выбрал метрику Macro-Recall\n",
    "Почему я выбрал эту метрику:\n",
    "Выбрал эту метрику потому что в статье (https://aclanthology.org/2020.findings-emnlp.148.pdf) она указывается как evaluation метрика для датасета sentiment. Macro-averaging позволит получать более честные показатели качества вне зависимости от наличия или отсутствия дизбаланса классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DeepAverageNetwork(nn.Module):\n",
    "    def __init__(self, embedding_matrix, dropout_prob: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.EmbeddingBag.from_pretrained(\n",
    "            embeddings=torch.from_numpy(embedding_matrix).to(torch.float32),\n",
    "            mode='mean',\n",
    "            padding_idx=0,\n",
    "            max_norm=10.0,\n",
    "            freeze=False,\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=embedding_matrix.shape[1], out_features=256)\n",
    "        self.output = nn.Linear(in_features=256, out_features=3)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.drop = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        data = self.drop(self.embeddings(x))\n",
    "        \n",
    "        data = self.drop(self.bn1(F.mish(self.linear1(data))))\n",
    "        \n",
    "        \n",
    "        return self.output(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepAverageNetwork(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepAverageNetwork(\n",
       "  (embeddings): EmbeddingBag(500002, 300, max_norm=10.0, mode=mean, padding_idx=0)\n",
       "  (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задайте функцию потерь и оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделайте цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a735cf29554e4c6d95e1d88467c95cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 0:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7673 | Loss: 0.5750\n",
      "Macro Recall: 0.7527 | Loss: 0.4889\n",
      "Macro Recall: 0.7292 | Loss: 0.5584\n",
      "Macro Recall: 0.7948 | Loss: 0.4877\n",
      "Macro Recall: 0.6637 | Loss: 0.6695\n",
      "Macro Recall: 0.6931 | Loss: 0.5835\n",
      "================================================================================\n",
      "Train Recall: 0.7222542874698018 | Val Recall: 0.5783691226729202\n",
      "Train Loss:   0.5958735207382705 | Val Loss: 0.8937701396644115\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a465d467d94fa0ab87f32143fa3921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 1:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7482 | Loss: 0.5228\n",
      "Macro Recall: 0.7470 | Loss: 0.4708\n",
      "Macro Recall: 0.7672 | Loss: 0.5208\n",
      "Macro Recall: 0.7301 | Loss: 0.6854\n",
      "Macro Recall: 0.7573 | Loss: 0.5903\n",
      "Macro Recall: 0.7312 | Loss: 0.5823\n",
      "================================================================================\n",
      "Train Recall: 0.7227410157242319 | Val Recall: 0.5694498305257799\n",
      "Train Loss:   0.5955523467865311 | Val Loss: 0.8987070210278034\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddab9270bfc4449939560b432ae2802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 2:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.6867 | Loss: 0.5902\n",
      "Macro Recall: 0.7340 | Loss: 0.5473\n",
      "Macro Recall: 0.7872 | Loss: 0.4877\n",
      "Macro Recall: 0.7339 | Loss: 0.5537\n",
      "Macro Recall: 0.7799 | Loss: 0.4626\n",
      "Macro Recall: 0.6400 | Loss: 0.6486\n",
      "================================================================================\n",
      "Train Recall: 0.7263524601657144 | Val Recall: 0.5618541093224637\n",
      "Train Loss:   0.5896269705783085 | Val Loss: 0.9086225815117359\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3307b8ff03e94ae4a17ea393656fafeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 3:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.6921 | Loss: 0.5278\n",
      "Macro Recall: 0.7075 | Loss: 0.5849\n",
      "Macro Recall: 0.6799 | Loss: 0.6431\n",
      "Macro Recall: 0.6951 | Loss: 0.6491\n",
      "Macro Recall: 0.7230 | Loss: 0.5186\n",
      "Macro Recall: 0.7845 | Loss: 0.5962\n",
      "================================================================================\n",
      "Train Recall: 0.7314144413241598 | Val Recall: 0.5702282949118392\n",
      "Train Loss:   0.583167428562955 | Val Loss: 0.9338757544755936\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca12add249d94853b7a1f2b87679b3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 4:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7559 | Loss: 0.5504\n",
      "Macro Recall: 0.7135 | Loss: 0.5736\n",
      "Macro Recall: 0.7965 | Loss: 0.5482\n",
      "Macro Recall: 0.7737 | Loss: 0.4943\n",
      "Macro Recall: 0.7538 | Loss: 0.5143\n",
      "Macro Recall: 0.7347 | Loss: 0.6324\n",
      "================================================================================\n",
      "Train Recall: 0.7392948673019144 | Val Recall: 0.5598255471673194\n",
      "Train Loss:   0.5708809673619204 | Val Loss: 0.969649001955986\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8433f6a86a054d1cb9eac47afc34ff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 5:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8445 | Loss: 0.4704\n",
      "Macro Recall: 0.8106 | Loss: 0.5158\n",
      "Macro Recall: 0.7773 | Loss: 0.5068\n",
      "Macro Recall: 0.7323 | Loss: 0.4639\n",
      "Macro Recall: 0.7387 | Loss: 0.5516\n",
      "Macro Recall: 0.7173 | Loss: 0.6142\n",
      "================================================================================\n",
      "Train Recall: 0.7488325507079723 | Val Recall: 0.5678088905937008\n",
      "Train Loss:   0.5524403551379505 | Val Loss: 0.9772221222519875\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1823ad53ea543b797a70177302591dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 6:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7900 | Loss: 0.5943\n",
      "Macro Recall: 0.7829 | Loss: 0.4443\n",
      "Macro Recall: 0.8218 | Loss: 0.4750\n",
      "Macro Recall: 0.8071 | Loss: 0.4673\n",
      "Macro Recall: 0.7609 | Loss: 0.5798\n",
      "Macro Recall: 0.7081 | Loss: 0.5816\n",
      "================================================================================\n",
      "Train Recall: 0.7578751356897246 | Val Recall: 0.5715332487484387\n",
      "Train Loss:   0.533456915733861 | Val Loss: 0.9732252210378647\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972940f5a71040969b068e03ac529d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 7:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8331 | Loss: 0.4781\n",
      "Macro Recall: 0.7897 | Loss: 0.4474\n",
      "Macro Recall: 0.7707 | Loss: 0.5443\n",
      "Macro Recall: 0.8182 | Loss: 0.4855\n",
      "Macro Recall: 0.8057 | Loss: 0.5434\n",
      "Macro Recall: 0.6855 | Loss: 0.6372\n",
      "================================================================================\n",
      "Train Recall: 0.77083445028148 | Val Recall: 0.5549722195291815\n",
      "Train Loss:   0.5146779551559469 | Val Loss: 1.0257541984319687\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94cae9346f54362b2ac2a0c24318141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 8:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7940 | Loss: 0.4570\n",
      "Macro Recall: 0.8460 | Loss: 0.3909\n",
      "Macro Recall: 0.8178 | Loss: 0.4544\n",
      "Macro Recall: 0.7673 | Loss: 0.5412\n",
      "Macro Recall: 0.8319 | Loss: 0.4592\n",
      "Macro Recall: 0.7850 | Loss: 0.5135\n",
      "================================================================================\n",
      "Train Recall: 0.7807107868203533 | Val Recall: 0.5582354822861152\n",
      "Train Loss:   0.4981564911139779 | Val Loss: 1.0450151711702347\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4971523c4a73416798525cd3551e6295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 9:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8077 | Loss: 0.4640\n",
      "Macro Recall: 0.7381 | Loss: 0.5459\n",
      "Macro Recall: 0.8009 | Loss: 0.5154\n",
      "Macro Recall: 0.8014 | Loss: 0.4318\n",
      "Macro Recall: 0.8799 | Loss: 0.4055\n",
      "Macro Recall: 0.7781 | Loss: 0.4369\n",
      "================================================================================\n",
      "Train Recall: 0.7888682048497432 | Val Recall: 0.573706356934205\n",
      "Train Loss:   0.48247334519688156 | Val Loss: 1.0920395851135254\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baea12cd8a62438185e98022b7425df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 10:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.7819 | Loss: 0.4676\n",
      "Macro Recall: 0.8422 | Loss: 0.4015\n",
      "Macro Recall: 0.8111 | Loss: 0.4248\n",
      "Macro Recall: 0.7862 | Loss: 0.5513\n",
      "Macro Recall: 0.7018 | Loss: 0.5499\n",
      "Macro Recall: 0.8135 | Loss: 0.4711\n",
      "================================================================================\n",
      "Train Recall: 0.7944935597604896 | Val Recall: 0.5694053953547624\n",
      "Train Loss:   0.46672896644314465 | Val Loss: 1.1065258495509624\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd274a89f80348448839ebf8b597cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 11:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.9055 | Loss: 0.3394\n",
      "Macro Recall: 0.8113 | Loss: 0.4746\n",
      "Macro Recall: 0.6709 | Loss: 0.5427\n",
      "Macro Recall: 0.8425 | Loss: 0.3663\n",
      "Macro Recall: 0.7653 | Loss: 0.5388\n",
      "Macro Recall: 0.8557 | Loss: 0.3927\n",
      "================================================================================\n",
      "Train Recall: 0.7992947527732377 | Val Recall: 0.5593539137842934\n",
      "Train Loss:   0.458872696431745 | Val Loss: 1.1473278924822807\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa42a31ddb44965a1980fea365964e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 12:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8688 | Loss: 0.3308\n",
      "Macro Recall: 0.8126 | Loss: 0.3969\n",
      "Macro Recall: 0.7974 | Loss: 0.4699\n",
      "Macro Recall: 0.8234 | Loss: 0.4078\n",
      "Macro Recall: 0.8149 | Loss: 0.3979\n",
      "Macro Recall: 0.7806 | Loss: 0.5387\n",
      "================================================================================\n",
      "Train Recall: 0.8034676759022915 | Val Recall: 0.5574925543279974\n",
      "Train Loss:   0.44890326720659807 | Val Loss: 1.1460245065391064\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669e3aec105c4f1cbb74934d9574018b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 13:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8224 | Loss: 0.4130\n",
      "Macro Recall: 0.8280 | Loss: 0.4384\n",
      "Macro Recall: 0.7239 | Loss: 0.5226\n",
      "Macro Recall: 0.8196 | Loss: 0.4001\n",
      "Macro Recall: 0.7561 | Loss: 0.4639\n",
      "Macro Recall: 0.8327 | Loss: 0.4349\n",
      "================================================================================\n",
      "Train Recall: 0.8062532056483726 | Val Recall: 0.5517969489488477\n",
      "Train Loss:   0.44574729902069776 | Val Loss: 1.1422088965773582\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12ab7194f4e444faa324fd859683a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 14:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Recall: 0.8095 | Loss: 0.4445\n",
      "Macro Recall: 0.8742 | Loss: 0.3574\n",
      "Macro Recall: 0.7819 | Loss: 0.5080\n",
      "Macro Recall: 0.7840 | Loss: 0.4658\n",
      "Macro Recall: 0.8296 | Loss: 0.3482\n",
      "Macro Recall: 0.8036 | Loss: 0.5422\n",
      "================================================================================\n",
      "Train Recall: 0.8081457011673017 | Val Recall: 0.557209902146611\n",
      "Train Loss:   0.44476676680126775 | Val Loss: 1.1629686951637268\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148c1f4d714445b2aea14f4afd3d8782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing...:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Test Recall: 0.5106\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 15  # Задайте количество эпох\n",
    "log_frequency = 70\n",
    "train_loss = []\n",
    "train_recall = []\n",
    "val_loss = []\n",
    "val_recall = []\n",
    "\n",
    "warmup_ratio = 0.3\n",
    "num_training_steps = len(train_loader) * NUM_EPOCHS\n",
    "num_warmup = int(round(num_training_steps * warmup_ratio))\n",
    "\n",
    "lr_sched = get_cosine_schedule_with_warmup(optimizer=optim, num_training_steps=num_training_steps, num_warmup_steps=num_warmup)\n",
    "\n",
    "for n_epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    epoch_loss = []\n",
    "    for i, (x, y) in enumerate(tqdm(train_loader, desc=f\"Train Epoch {n_epoch}\")):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits = model(x)\n",
    "        loss_value = loss(logits, y)\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "        lr_sched.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        epoch_loss.append(loss_value.item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1)\n",
    "            y_pred_batch = y_pred_batch.detach().cpu().numpy()\n",
    "            y_true_batch = y.detach().cpu().numpy()\n",
    "            \n",
    "            y_pred += list(y_pred_batch)\n",
    "            y_true += list(y_true_batch)\n",
    "            if i % log_frequency == 0:\n",
    "                recall = recall_score(y_true_batch, y_pred_batch, average='macro')\n",
    "                print(f\"Macro Recall: {recall:.4f} | Loss: {loss_value.item():.4f}\")\n",
    "                \n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    ep_train_recall = recall_score(y_true, y_pred, average='macro')\n",
    "    train_recall.append(ep_train_recall)\n",
    "\n",
    "    # validation\n",
    "    epoch_val_loss = []\n",
    "    with torch.no_grad():\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for x, y in valid_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            epoch_val_loss.append(loss(logits, y).item())\n",
    "            y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1).cpu().numpy()\n",
    "            y_true_batch = y.cpu().numpy()\n",
    "            \n",
    "            y_pred += list(y_pred_batch)\n",
    "            y_true += list(y_true_batch)\n",
    "            \n",
    "        ep_val_recall = recall_score(y_true, y_pred, average='macro')\n",
    "        val_recall.append(ep_val_recall)\n",
    "        val_loss.append(np.mean(epoch_val_loss))\n",
    "    \n",
    "    print(\"==\"*40)\n",
    "    print(f\"Train Recall: {ep_train_recall:^5} | Val Recall: {ep_val_recall:^5}\")\n",
    "    print(f\"Train Loss:   {np.mean(epoch_loss):^5} | Val Loss: {np.mean(epoch_val_loss):^5}\")\n",
    "    print(\"==\"*40)\n",
    "    \n",
    "# test\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, desc='Testing...'):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits = model(x)\n",
    "        y_pred_batch = torch.argmax(torch.softmax(logits, -1), -1).cpu().numpy()\n",
    "        y_true_batch = y.cpu().numpy()\n",
    "\n",
    "        y_pred += list(y_pred_batch)\n",
    "        y_true += list(y_true_batch)\n",
    "        \n",
    "test_recall = recall_score(y_true, y_pred, average='macro')\n",
    "print(\"++\"*40)\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(\"++\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.28      0.39      3972\n",
      "     neutral       0.57      0.55      0.56      5937\n",
      "    positive       0.35      0.70      0.46      2375\n",
      "\n",
      "    accuracy                           0.49     12284\n",
      "   macro avg       0.52      0.51      0.47     12284\n",
      "weighted avg       0.55      0.49      0.49     12284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=train_dataset.features['label'].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=train_dataset.features['label'].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "Напишите небольшой отчет о проделанной работе. Что удалось, в чем не уверены, что делать дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Получилось сделать модель с предлагаемой архитектурой\n",
    "- Получилось реализовать процесс предобработки текста и процесс обучения\n",
    "- Модель не позволяет добится каких-то серьезных результатов и переобучается несмотря на применение dropout и batchnorm\n",
    "- Качество работы модели в общем случае не зависит от глубины MLP-компоненты, достаточно и одного слоя внутри + выходного слоя\n",
    "- Чаще всего модель путает нейтральный сентимент с позитивным, негативный с нейтральным и негативный с позитивным\n",
    "- Возможно стоит добавить способ учитывать контекст или позицию токенов(можно попробовать добавить позиционные эмбеддинги как в трансформерах) или добавить кастомные веса для классов в лосс-функцию.\n",
    "- Ввиду того что в токенизированном тексте полно UNK-токенов, то думаю стоит добавить посимвольные эмбеддинги + посимвольную cnn(как реализовано в elmo в allennlp)\n",
    "- С другой стороны это очень простая модель, мб не стоит ожидать от нее хороших результатов.\n",
    "- Так-же возможны пробелы в разметке нейтрального и негативного классов, в то время как позитивный класс размечен хорошо и модель реже всего путает его с каким-то другим классом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
